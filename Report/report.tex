\documentclass[a4paper,12pt]{article}

\usepackage[utf8x]{inputenc}
\usepackage[english]{babel}
\usepackage[margin=1in,includefoot]{geometry}

\usepackage{pgfplots}
\pgfplotsset{width=15cm,compat=1.12}
\usetikzlibrary{arrows}

\usepackage{indentfirst}

\usepackage[backref=false,pagebackref=true,citecolor=blue]{hyperref}
\hypersetup{colorlinks=true,urlcolor=blue,pdfborder={0 0 0}}

\setlength{\parindent}{2em}
\setlength{\parskip}{1em}

%\renewcommand{\arraystretch}{2}
%\renewcommand{\familydefault}{\sfdefault}

\newcommand{\refspace}{\vspace{-2mm}}
\newcommand{\redarrow}{\textcolor{blue}{$\mathbf{\Rightarrow}$}}
\makeatletter
\def\BR@@bibitem#1#2\par{
	\let\backrefprint\BR@backrefprint
	\def\@linkcolor{black}
	\BRorg@bibitem{#1}#2\redarrow \thinspace \BR@backref{#1}
}
\makeatother

\author{Roland Bogosi}
\title{Market Prediction}

\begin{document}
\thispagestyle{empty}
	Â 
	\begin{center}
		\vspace{3.1in}
		
		{\sffamily\huge Market Prediction using Neural Networks}
		
		\vspace{0.4in}
		
		{\sffamily\LARGE Assignment Report}
		
		\vspace{0.3in}
		
		{\sffamily\Large January 4th, 2016}
		
		\vspace{3.2in}
	\end{center}
	
	\begin{flushright}
		{\sffamily\itshape\Large Roland Bogosi}
	\end{flushright}

\newpage
\thispagestyle{empty}
\section*{Table of Contents}

	\begingroup
	\renewcommand{\section}[2]{}
	\hypersetup{linkcolor=blue}
	\setlength{\parskip}{0em}
	\tableofcontents
	\endgroup

\newpage
\section{Introduction}

	The purpose of this classroom assignment is to use neural networks in order to predict stock market or currency fluctuations. There are many ways to tackle this time-series prediction problem, each of them having their own pros and cons:
	
	\textbf{Index Prediction} -- Try to teach the individual values of a series. This way the neural network will receive an input which in some form indicates the day we would like to evaluate it/predict for and as the output of the network, we get the prediction.
	
	\textbf{Indicator Prediction} -- Transform the dataset into indicators used during stock analysis, and teach the neural network the pattern of these. This way, the neural network will not be able to predict the index itself, but it should be able to predict the trend within the indicator that is used to make the actual decision if a stock should be purchased or not.
		
	In both cases, as described in \cite{op1997stock}, one of the main challenges was to decide what inputs and outputs should the neural network be trained for. My initial thought was to feed the date as input, and get the predicted index as the output. However, upon experimentation I learned that this model would not work, and after further researching, the winner method seemed to be having one or more input variables which are the index values of the previous days.
	
	For the purposes of this classroom assignment, I decided focusing on using currency rates, since stock data has way too many outside factors influencing it. I would have had to analyze these outside factors for each stock individually and encode it as an input to the neural network in some form, in order to create an accurate model. For example, the stock of a car manufacturing company might go up when they hold a press release and announce a model, and might suddenly go down if the new model gets a bad review from a reputable source or an issue arises with it, possibly needing call-backs.

\newpage
\section{Structure}

	\tikzstyle{es} = [-triangle 60]
	\begin{figure}[!htbp]
		\centering
		\begin{tikzpicture}[x=1.5cm,y=1.5cm]
			\draw [] (0,0) ellipse (0.5 and 0.5);
			\draw [] (0,1.5) ellipse (0.5 and 0.5);
			\draw [] (0,-1.5) ellipse (0.5 and 0.5);
			\draw [] (2.5,0) ellipse (0.5 and 0.5);
			\draw [] (-2.5,0) ellipse (0.5 and 0.5);
			\node (v1) at (-2,0) {};
			\node (v2) at (-0.5,1.5) {};
			\node (v3) at (-0.5,0) {};
			\node (v4) at (-0.5,-1.5) {};
			\node (v5) at (0.5,1.5) {};
			\node (v7) at (0.5,0) {};
			\node (v8) at (0.5,-1.5) {};
			\node (v6) at (2,0) {};
			\draw [es] (v1) edge (v2);
			\draw [es] (v1) edge (v3);
			\draw [es] (v1) edge (v4);
			\draw [es] (v5) edge (v6);
			\draw [es] (v7) edge (v6);
			\draw [es] (v8) edge (v6);
			\node (v9) at (-4.5,0) {};
			\node (v12) at (4.5,0) {};
			\node (v10) at (-3,0) {};
			\draw [es] (v9) edge (v10);
			\node (v11) at (3,0) {};
			\draw [es] (v11) edge (v12);
			\node at (-2.5,2.5) {\shortstack{Input\\layer}};
			\node at (0,2.5) {\shortstack{Hidden\\layers}};
			\node at (2.5,2.5) {\shortstack{Output\\layer}};
			\node at (0.5,2) {$w_1$};
			\node at (0.5,0.5) {$w_2$};
			\node at (0.5,-1) {$w_3$};
			\node at (3,0.5) {$y_1$};
			\node at (-2,0.5) {$x_1$};
		\end{tikzpicture}
		\caption{Structure of the Neural Network}
		\label{neurnet}
	\end{figure}

	The neural network shown in figure \ref{neurnet} has a single input, $x_1$, which is the index of the stock or currency for that day. The output of the network, $y_1$, is the predicted value for the \textit{next} day.
	
	The number of hidden layers in the network varies based on how many training samples (days) we would like to train the network on, and also on how many days we would like to predict beyond the training samples. While the general rule is to have $x_n \cdot 2$ hidden layers, I evaluated this during several trial and error runs and it did not seem to work well with this application. Even with the momentum learning parameter ($m$) set to a high value, $0.9 < m < 1$, the neural network was not able to accurately fit the data, it only generated an approximate oscillation.
	
	The neural network is trained with backpropagation, which is a supervised learning method. The network weights are randomly initialized to values between the range of $[0.25..0.35]$, which was determined to yield the best results after a few trial and error runs. The activation function used with the trainer is sigmoid: $f(x) = \frac{1}{e^{-\alpha \cdot x} + 1}$
	
	After some experimentation, I found the number of hidden layers in order to accurately fit the data as a result of $1,000$ iterations of the backpropagation teacher algorithm, to be roughly equal to the size of the training samples.

\section{Experiments}

	\begin{figure}[!htbp]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
			xlabel={Days},
			ylabel={Index},
			legend pos=north west,
			ymajorgrids=true,
			grid style=dashed,
			legend entries={Actual Rates,Estimate,Prediction}
		]
			\addplot[blue,mark=*]  table {eur_usd_august_30.txt};
			\addplot[red,mark=*]   table {eur_usd_august_30_neuron.txt};
			\addplot[green,mark=*] table {eur_usd_august_30_neuron_pred.txt};
		\end{axis}
		\end{tikzpicture}
		\caption{EUR/USD Rates for August 2015}
		\label{eurusd2015}
	\end{figure}
	
	\begin{figure}[!htbp]
		\centering
		\begin{tikzpicture}
		\begin{axis}[
			xlabel={Days},
			ylabel={Index},
			legend pos=north west,
			ymajorgrids=true,
			grid style=dashed,
			legend entries={Actual Rates,Estimate,Prediction}
		]
			\addplot[blue,mark=*]  table {eur_usd_august_30.txt};
			\addplot[red,mark=*]   table {eur_usd_august_30_genetic.txt};
			\addplot[green,mark=*] table {eur_usd_august_30_genetic_pred.txt};
		\end{axis}
		\end{tikzpicture}
		\caption{EUR/USD Rates for August 2015}
		\label{eurusd2015}
	\end{figure}
	
	The output of the genetic algorithm, meaning the fittest chromosome, after $1,000$ iterations is the following equation:\\
	$$ (b \cdot \frac{b \cdot \frac{c}{b}}{\frac{c \cdot b}{b}}) \cdot \frac{a}{(b \cdot c) \cdot \frac{\frac{c}{d}}{b}} $$
	
	Which can be simplified to:\\
	$$ \frac{a \cdot b \cdot c}{2} $$
	
\newpage
\section{Bibliography}

	\begingroup
	\renewcommand{\section}[2]{}
		\bibliography{report} 
		\bibliographystyle{ieeetr}
	\endgroup

\end{document}